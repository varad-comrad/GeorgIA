{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import shutil\n",
    "import csv\n",
    "import json\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from random import random\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset    \n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import Compose\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGen:\n",
    "    def __init__(self, zip_path, split_ratio, transforms) -> None:\n",
    "        self.zip_path = zip_path\n",
    "        self.split_ratio = split_ratio\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def create_label_encs(self):\n",
    "        label2id, id2label = {}, {}\n",
    "        with zipfile.ZipFile(self.zip_path, 'r') as zip_file:\n",
    "            for name in zip_file.namelist():\n",
    "                if '/' in name:\n",
    "                    label = name.split('/')[1]\n",
    "                    if label not in label2id:\n",
    "                        label2id[label] = len(label2id)\n",
    "                        id2label[len(id2label)] = label\n",
    "        self.label2id = label2id\n",
    "        self.id2label = id2label\n",
    "        return label2id, id2label\n",
    "\n",
    "    def generate(self, **loader_params):\n",
    "        label2id, id2label = self.create_label_encs()\n",
    "        with zipfile.ZipFile(self.zip_path, 'r') as zip_file:\n",
    "            new_path = pathlib.Path(self.zip_path).parent / zip_file.namelist()[0].split('/')[0]\n",
    "            zip_file.extractall('datasets')\n",
    "        self.split(new_path)\n",
    "        train_dataset = datasets.ImageFolder(\n",
    "            new_path.parent / 'train', transform=self.transforms['train'])\n",
    "        train_loader = DataLoader(train_dataset, **loader_params)\n",
    "        valid_dataset = datasets.ImageFolder(\n",
    "            new_path.parent / 'valid', transform=self.transforms['valid'])\n",
    "        valid_loader = DataLoader(valid_dataset, **loader_params)\n",
    "        test_dataset = datasets.ImageFolder(\n",
    "            new_path.parent / 'test', transform=self.transforms['test'])\n",
    "        test_loader = DataLoader(test_dataset, **loader_params)\n",
    "        self.delete_path(new_path)\n",
    "        return {\n",
    "            'train_loader': train_loader,\n",
    "            'valid_loader': valid_loader,\n",
    "            'test_loader': test_loader,\n",
    "            'label2id': label2id,\n",
    "            'id2label': id2label,\n",
    "            'train_dataset': train_dataset,\n",
    "            'valid_dataset': valid_dataset,\n",
    "            'test_dataset': test_dataset\n",
    "        }\n",
    "\n",
    "    def split(self, path: pathlib.Path):\n",
    "        train_path = (path.parent / 'train')\n",
    "        valid_path = (path.parent / 'valid')\n",
    "        test_path = (path.parent / 'test')\n",
    "\n",
    "        for label in path.iterdir():\n",
    "            (train_path / label.name).mkdir(parents=True)\n",
    "            (valid_path / label.name).mkdir(parents=True)\n",
    "            (test_path / label.name).mkdir(parents=True)\n",
    "            for img in label.iterdir():\n",
    "                rand = random()\n",
    "                if rand < self.split_ratio[0]:\n",
    "                    img.rename(train_path / label.name / img.name)\n",
    "                elif rand < self.split_ratio[0] + self.split_ratio[1]:\n",
    "                    img.rename(valid_path / label.name / img.name)\n",
    "                else:\n",
    "                    img.rename(test_path / label.name / img.name)\n",
    "\n",
    "\n",
    "    def delete_path(self, path):\n",
    "        shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    'train': Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gen = DatasetGen('datasets/geolocation-geoguessr-images-50k.zip', (0.8, 0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = ds_gen.generate(batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    '''\n",
    "    Convolutional block responsible for getting the hidden state of the image\n",
    "    '''\n",
    "    def __init__(self, input_channel, out_channels: list[int], filter_sizes: list[int], strides: list[int], batch_norm: list[bool], pooling_args: list | None = None, device: torch.device = torch.device('cuda')) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential()\n",
    "        aux = input_channel\n",
    "        for i, out_channel, filter_size, stride, norm in enumerate(zip(out_channels, filter_sizes, strides, batch_norm)):\n",
    "            self.layers.add_module(f'conv_{i}', nn.Conv2d(aux, out_channel, filter_size, stride, padding='same', device=device))\n",
    "            aux = out_channel\n",
    "            if norm:\n",
    "                self.layers.add_module(f'batch_norm_{i}', nn.BatchNorm2d(out_channel, device=device))\n",
    "            self.layers.add_module(f'relu_{i}', nn.ReLU())\n",
    "        if pooling_args is not None:\n",
    "            self.layers.add_module('max_pool', nn.MaxPool2d(*pooling_args, device=device))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channels) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channels[0][0], 1, stride=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channels[2][0], 1, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels[2][0], out_channels[2][1], 3, stride=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channels[3][0], 1, stride=1, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels[3][0], out_channels[3][1], 5, stride=1, padding='same'),\n",
    "            nn.ReLU()    \n",
    "        )\n",
    "\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(3, stride=1, padding='same'),\n",
    "            nn.Conv2d(in_channel, out_channels[4][0], 1, stride=1, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        x4 = self.branch4(x)\n",
    "\n",
    "        out = torch.cat([x1, x2, x3, x4], 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel1(nn.Module): #? Custom model made from scratch\n",
    "    def __init__(self, n_labels) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "    def forward(self, x): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, n_labels) -> None:\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.vgg19(pretrained=True)\n",
    "        self.model.training = False\n",
    "        self.model.classifier[6] = nn.Linear(4096, 1024)\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_labels)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.linear(x)\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback:\n",
    "    def __init__(self) -> None:\n",
    "        self.epoch_counter = 0\n",
    "        self.batch_counter = 0\n",
    "\n",
    "    def on_train_begin(self): \n",
    "        self.batch_counter = 0\n",
    "\n",
    "    def on_train_end(self):\n",
    "        return None\n",
    "\n",
    "    def on_epoch_begin(self): \n",
    "        return None\n",
    "    \n",
    "    def on_epoch_end(self, val_loss, model, *args): \n",
    "        self.epoch_counter += 1\n",
    "    \n",
    "    def on_batch_begin(self):\n",
    "        return None\n",
    "    \n",
    "    def on_batch_end(self): \n",
    "        self.batch_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelCheckpoint(Callback):\n",
    "    def __init__(self, path) -> None:\n",
    "        super().__init__()\n",
    "        self.path = pathlib.Path(path)\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, val_loss, model, *args):\n",
    "        super().on_epoch_end(val_loss, model, *args)\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            torch.save(model.state_dict(), self.path)\n",
    "\n",
    "class EarlyStopping(Callback):\n",
    "    def __init__(self, patience, restore_best_weights=False, checkpoint: str|bool=False) -> None:\n",
    "        super().__init__()\n",
    "        self.patience = patience\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.checkpoint = checkpoint\n",
    "\n",
    "        if self.checkpoint:\n",
    "            self.model_checkpoint = ModelCheckpoint(self.checkpoint)\n",
    "        if self.restore_best_weights:\n",
    "            self.best_weights = None\n",
    "\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, val_loss, model, *args):\n",
    "        super().on_epoch_end(val_loss, model, *args)\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f\"Early stopping on epoch {self.epoch_counter} with val_loss: {val_loss}\")\n",
    "                return True\n",
    "            \n",
    "class LearningRateScheduler(Callback):\n",
    "    def __init__(self, lr_scheduler) -> None:\n",
    "        super().__init__()\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "\n",
    "    def on_epoch_end(self, val_loss, model, *args):\n",
    "        super().on_epoch_end(val_loss, model)\n",
    "        self.lr_scheduler(self.epoch_counter, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, loss_func, optimizer, epochs, callbacks: None | list[Callback] = None):\n",
    "    for epoch in range(epochs):\n",
    "        if any(callback.on_epoch_begin() for callback in callbacks):\n",
    "            break\n",
    "        model.train()\n",
    "        if any(callback.on_train_begin() for callback in callbacks):\n",
    "            break\n",
    "        for images, labels in train_loader:\n",
    "            if any(callback.on_batch_begin() for callback in callbacks):\n",
    "                break\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = loss_func(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if any(callback.on_batch_end() for callback in callbacks):\n",
    "                break\n",
    "        if any(callback.on_train_end() for callback in callbacks):\n",
    "            break\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0\n",
    "            val_samples = 0\n",
    "            for images, labels in val_loader:\n",
    "                output = model(images)\n",
    "                loss = loss_func(output, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_samples += 1\n",
    "            avg_val_loss = val_loss / val_samples\n",
    "            print(f\"Epoch: {epoch}, Validation Loss: {avg_val_loss}\")\n",
    "        if any(callback.on_epoch_end(avg_val_loss, model) for callback in callbacks):\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
